{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMOTE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OdrPFD51cvL",
        "outputId": "a6b07b8e-4575-4782-de09-6626aac3146a"
      },
      "source": [
        "import imblearn\n",
        "print(imblearn.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J4CUhP22P7f",
        "outputId": "5b237f4c-19b0-4b2b-e653-336bb3121d47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zkOwXKC15SP",
        "outputId": "396d2470-467a-499f-e693-1ede1d4d0160"
      },
      "source": [
        "# load dataset\n",
        "from numpy import genfromtxt\n",
        "import os\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import svm\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# load a list of files\n",
        "def load_group(filenames, prefix=''):\n",
        "    loaded = list()\n",
        "    for name in filenames:\n",
        "        data = genfromtxt(prefix + name, delimiter=',')\n",
        "        if 'x' in name:\n",
        "            loaded.append(data)\n",
        "        if 'y' in name:\n",
        "            xData = genfromtxt(prefix + name[:-5] + 'x.csv', delimiter=',')\n",
        "            interpolated_data = nn_interpolate(data, (xData.shape[0], xData.shape[1]))\n",
        "            loaded.append(interpolated_data)\n",
        "    return loaded\n",
        "\n",
        "\n",
        "def load_dataset(group, prefix=''):\n",
        "    filenamesX = list()\n",
        "    filenamesY = list()\n",
        "    # body acceleration\n",
        "    for file in os.listdir(prefix):\n",
        "        if file.startswith(group) and file.endswith('__x.csv'):\n",
        "            filenamesX += [file]\n",
        "    # load input data\n",
        "    X = load_group(filenamesX, prefix)\n",
        "    # load class output\n",
        "    for file in os.listdir(prefix):\n",
        "        if file.startswith(group) and file.endswith('__y.csv'):\n",
        "            filenamesY += [file]\n",
        "\n",
        "    y = load_group(filenamesY, prefix)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def nn_interpolate(A, new_size):\n",
        "    \"\"\"Vectorized Nearest Neighbor Interpolation\"\"\"\n",
        "\n",
        "    old_size = A.shape\n",
        "    row_ratio, col_ratio = np.array(new_size) / np.array(old_size)\n",
        "\n",
        "    # row wise interpolation\n",
        "    row_idx = (np.ceil(range(1, 1 + int(old_size[0] * row_ratio)) / row_ratio) - 1).astype(int)\n",
        "\n",
        "    final_matrix = A[row_idx]\n",
        "\n",
        "    return final_matrix\n",
        "\n",
        "\n",
        "# # summarize the balance of classes in an output variable column\n",
        "# def class_breakdown(data):\n",
        "#     # convert the numpy array into a dataframe\n",
        "#     df = DataFrame(data)\n",
        "#     # group data by the class value and calculate the number of rows\n",
        "#     counts = df.groupby(0).size()\n",
        "#     # retrieve raw rows\n",
        "#     counts = counts.values\n",
        "#     # summarize\n",
        "#     for i in range(len(counts)):\n",
        "#         percent = counts[i] / len(df) * 100\n",
        "#         print('Class=%d, total=%d, percentage=%.3f' % (i + 1, counts[i], percent))\n",
        "\n",
        "def pre_processing(X):\n",
        "    len_sequences = []\n",
        "    for one_file in X:\n",
        "        for one_seq in one_file:\n",
        "            len_sequences.append(len(one_seq))\n",
        "\n",
        "    to_pad = 70172\n",
        "    new_seq = []\n",
        "    for one_file in X:\n",
        "        for one_seq in one_file:\n",
        "            len_one_seq = len(one_seq)\n",
        "            last_val = one_seq[-1]\n",
        "            n = to_pad - len_one_seq\n",
        "\n",
        "            to_concat = np.repeat(one_seq[-1], n).reshape(6, n).transpose()\n",
        "            new_one_seq = np.concatenate([one_seq, to_concat])\n",
        "            new_seq.append(new_one_seq)\n",
        "\n",
        "        final_seq = np.stack(new_seq)\n",
        "    seq_len = 60000\n",
        "    final_seq = sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float',\n",
        "                                       truncating='post')\n",
        "\n",
        "def data_finalize(trainX, trainy, valX, valY):\n",
        "    # train, train_target, validation, val_target = [], [], [], []\n",
        "    trainSubject, trainTarget, validationSubject, validationTarget = [], [], [], []\n",
        "    for i in range(0, len(trainX)):\n",
        "        trainSubject.append(np.vstack(trainX[i]))\n",
        "\n",
        "    train = np.vstack(trainSubject)\n",
        "\n",
        "    for i in range(0, len(trainy)):\n",
        "        trainTarget.append(np.concatenate(trainy[i]))\n",
        "\n",
        "    train_target = np.concatenate(trainTarget)\n",
        "\n",
        "    for i in range(0, len(valX)):\n",
        "        validationSubject.append(np.vstack(valX[i]))\n",
        "\n",
        "    validation = np.vstack(validationSubject)\n",
        "\n",
        "    for i in range(0, len(valY)):\n",
        "        validationTarget.append(np.concatenate(valY[i]))\n",
        "\n",
        "    val_target = np.concatenate(validationTarget)\n",
        "\n",
        "    return train, train_target, validation, val_target\n",
        "\n",
        "def create_MLmodel(trainX, trainy, valX, valY):\n",
        "    clf = svm.SVC()\n",
        "    clf.fit(trainX, trainy)\n",
        "\n",
        "# load all train\n",
        "trainX = list()\n",
        "trainy = list()\n",
        "validationX = list()\n",
        "validationY = list()\n",
        "for i in range(1, 9):\n",
        "    trX, trY = load_dataset('subject_00' + str(i), '/content/gdrive/MyDrive/data/')\n",
        "    trainX.append(trX)\n",
        "    trainy.append(trY)\n",
        "for i in range(6, 9):\n",
        "    valX, valY = load_dataset('subject_00' + str(i), '/content/gdrive/MyDrive/data/')\n",
        "    validationX.append(valX)\n",
        "    validationY.append(valY)\n",
        "train, train_target, val, val_target = data_finalize(trainX, trainy, validationX, validationY)\n",
        "train = train[:-2, :]\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsvnYS64och",
        "outputId": "0350cff1-0d8b-49ce-a3c1-5210e1a0b9a7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "counter = Counter(train_target)\n",
        "print(counter)\n",
        "\n",
        "oversample = SMOTE()\n",
        "Xsmote, Ysmote = oversample.fit_resample(train, train_target)\n",
        "\n",
        "counter = Counter(Ysmote)\n",
        "print(counter)\n",
        "\n",
        "# trainX, testX, trainy, testy = train_test_split(train, train_target, test_size=0.5, stratify=y)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "# print(trainX.shape)\n",
        "# print(train_target.shap)\n",
        "model.fit(Xsmote, Ysmote)\n",
        "yhat = model.predict(val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0.0: 1006926, 3.0: 206434, 2.0: 73068, 1.0: 55216})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0.0: 1006926, 1.0: 1006926, 2.0: 1006926, 3.0: 1006926})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLvqC0VlBmZ5",
        "outputId": "065923c8-ffd3-4256-fe9d-20eb2755e446"
      },
      "source": [
        "print('Accuracy: %.3f' % accuracy_score(val_target, yhat))\n",
        "print('Precision: %.3f' % precision_score(val_target, yhat, average='micro'))\n",
        "print('Recall: %.3f' % recall_score(val_target, yhat, average='micro'))\n",
        "print('F-measure: %.3f' % f1_score(val_target, yhat, average='micro'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.357\n",
            "Precision: 0.357\n",
            "Recall: 0.357\n",
            "F-measure: 0.357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOX4uPM8Ck1O",
        "outputId": "4db082ec-7a20-43bd-e8df-8e2d0281a595"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVC_model = svm.SVC()\n",
        "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
        "# SVC_model.fit(train, train_target)\n",
        "KNN_model.fit(Xsmote, Ysmote)\n",
        "# print(accuracy_score(SVC_prediction, y_test))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVOLZN6VDtlS",
        "outputId": "48b733bc-7750-40f6-8abc-c892dd158baf"
      },
      "source": [
        "KNN_prediction = KNN_model.predict(val)\n",
        "print(accuracy_score(KNN_prediction, val_target))\n",
        "# But Confusion Matrix and Classification Report give more details about performance\n",
        "# print(confusion_matrix(SVC_prediction, y_test))\n",
        "print(classification_report(KNN_prediction, val_target))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7195762299589661\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.99      0.78    183351\n",
            "         1.0       0.99      0.32      0.48     33945\n",
            "         2.0       0.99      0.40      0.57     43167\n",
            "         3.0       0.96      0.53      0.68    117761\n",
            "\n",
            "    accuracy                           0.72    378224\n",
            "   macro avg       0.90      0.56      0.63    378224\n",
            "weighted avg       0.81      0.72      0.70    378224\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VzZnKs7FLX6",
        "outputId": "fb1b5703-90b7-4db6-b490-1b3bfe5bce2d"
      },
      "source": [
        "KNN_model = KNeighborsClassifier(n_neighbors=4)\n",
        "# SVC_model.fit(train, train_target)\n",
        "KNN_model.fit(Xsmote, Ysmote)\n",
        "KNN_prediction = KNN_model.predict(val)\n",
        "print(accuracy_score(KNN_prediction, val_target))\n",
        "# But Confusion Matrix and Classification Report give more details about performance\n",
        "# print(confusion_matrix(SVC_prediction, y_test))\n",
        "print(classification_report(KNN_prediction, val_target))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8028919370531749\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      1.00      0.85    212425\n",
            "         1.0       0.99      0.41      0.58     26195\n",
            "         2.0       0.99      0.49      0.66     34736\n",
            "         3.0       0.99      0.61      0.76    104868\n",
            "\n",
            "    accuracy                           0.80    378224\n",
            "   macro avg       0.93      0.63      0.71    378224\n",
            "weighted avg       0.85      0.80      0.79    378224\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUEIt_a8J7T1",
        "outputId": "187dff11-afe6-4352-c7c1-41d9ed97019d"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(Xsmote, Ysmote)\n",
        "y_pred = nb.predict(val)\n",
        "print(accuracy_score(y_pred, val_target))\n",
        "print(classification_report(y_pred, val_target))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2287083844494268\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.78      0.33     76876\n",
            "         1.0       0.17      0.04      0.06     50742\n",
            "         2.0       0.62      0.06      0.10    188383\n",
            "         3.0       0.21      0.22      0.21     62223\n",
            "\n",
            "    accuracy                           0.23    378224\n",
            "   macro avg       0.30      0.27      0.18    378224\n",
            "weighted avg       0.41      0.23      0.16    378224\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzdlfZ53UDFo",
        "outputId": "237b0537-8272-4a16-ba50-228eec267208"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfm = RandomForestClassifier(n_estimators=70, oob_score=True, n_jobs=-1, random_state=101, max_features=None, min_samples_leaf=30)\n",
        "rfm.fit(Xsmote, Ysmote)\n",
        "rfm_pred = rfm.predict(val)\n",
        "print(accuracy_score(y_pred, val_target))\n",
        "print(classification_report(y_pred, val_target))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2287083844494268\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.78      0.33     76876\n",
            "         1.0       0.17      0.04      0.06     50742\n",
            "         2.0       0.62      0.06      0.10    188383\n",
            "         3.0       0.21      0.22      0.21     62223\n",
            "\n",
            "    accuracy                           0.23    378224\n",
            "   macro avg       0.30      0.27      0.18    378224\n",
            "weighted avg       0.41      0.23      0.16    378224\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3KSyW2HOg8c",
        "outputId": "e78c0e42-8c64-47c9-eb9a-9cbee471d723"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
        "sgd.fit(Xsmote, Ysmote)\n",
        "y_pred_sgd = sgd.predict(val)\n",
        "print(accuracy_score(y_pred_sgd, val_target))\n",
        "print(classification_report(y_pred_sgd, val_target))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0648213756927112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.01      0.83      0.02      3560\n",
            "         1.0       0.01      0.10      0.03      1643\n",
            "         2.0       0.91      0.05      0.09    347702\n",
            "         3.0       0.09      0.22      0.13     25319\n",
            "\n",
            "    accuracy                           0.06    378224\n",
            "   macro avg       0.26      0.30      0.06    378224\n",
            "weighted avg       0.85      0.06      0.09    378224\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}